{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36068890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display  # type: ignore[import-not-found]\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.data.dataset import VideoDataset\n",
    "from src.utils.io import load_yaml\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c61f2c",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Load configuration and setup paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db802359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = Path.cwd().parent / 'configs' / 'default.yaml'\n",
    "config = load_yaml(config_path)\n",
    "\n",
    "print(f\"Project: {config['project']['name']}\")\n",
    "print(f\"Labels: {config['data']['labels']}\")\n",
    "print(f\"Num classes: {config['data']['num_classes']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50122962",
   "metadata": {},
   "source": [
    "## 2. Dataset Statistics\n",
    "\n",
    "Load dataset and examine basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if processed data exists\n",
    "data_dir = Path.cwd().parent / config['data']['processed_dir']\n",
    "\n",
    "if not data_dir.exists():\n",
    "    print(f\"⚠️ Data directory not found: {data_dir}\")\n",
    "    print(\"Please run preprocessing first:\")\n",
    "    print(\"  1. Extract frames: python scripts/extract_frames.py --input data/raw --output data/interim/frames\")\n",
    "    print(\"  2. Create splits: python scripts/split_dataset.py --input data/interim/frames --output data/processed\")\n",
    "else:\n",
    "    print(f\"✓ Data directory found: {data_dir}\")\n",
    "\n",
    "    # List splits\n",
    "    splits = [d.name for d in data_dir.iterdir() if d.is_dir()]\n",
    "    print(f\"Available splits: {splits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets (if data exists)\n",
    "if data_dir.exists():\n",
    "    labels = config['data']['labels']\n",
    "    num_frames = config['data']['preprocessing']['num_frames']\n",
    "\n",
    "    datasets = {}\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if (data_dir / split).exists():\n",
    "            try:\n",
    "                dataset = VideoDataset(\n",
    "                    data_dir=data_dir,\n",
    "                    labels=labels,\n",
    "                    split=split,\n",
    "                    num_frames=num_frames,\n",
    "                    transform=None,\n",
    "                )\n",
    "                datasets[split] = dataset\n",
    "                print(f\"{split:5s}: {len(dataset):4d} samples\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {split}: {e}\")\n",
    "else:\n",
    "    print(\"Skipping dataset loading (no data available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977c4c3",
   "metadata": {},
   "source": [
    "## 3. Class Distribution\n",
    "\n",
    "Analyze class balance across splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f981067",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dir.exists() and len(datasets) > 0:\n",
    "    # Collect class counts\n",
    "    class_counts = {}\n",
    "    for split, dataset in datasets.items():\n",
    "        class_counts[split] = dataset.get_class_counts()\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(class_counts).T\n",
    "    display(df)\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, len(datasets), figsize=(5 * len(datasets), 4))\n",
    "    if len(datasets) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, (split, counts) in enumerate(class_counts.items()):\n",
    "        axes[idx].bar(counts.keys(), counts.values())\n",
    "        axes[idx].set_title(f'{split.capitalize()} Split')\n",
    "        axes[idx].set_xlabel('Class')\n",
    "        axes[idx].set_ylabel('Count')\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd7460",
   "metadata": {},
   "source": [
    "## 4. Sample Visualization\n",
    "\n",
    "Visualize random samples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dir.exists() and 'train' in datasets:\n",
    "    dataset = datasets['train']\n",
    "\n",
    "    # Get random samples\n",
    "    num_samples = min(6, len(dataset))\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        video, label = dataset[idx]\n",
    "\n",
    "        # Get middle frame\n",
    "        mid_frame = video.shape[0] // 2\n",
    "        frame = video[mid_frame].permute(1, 2, 0).numpy()\n",
    "\n",
    "        # Display\n",
    "        axes[i].imshow(frame)\n",
    "        axes[i].set_title(f'Sample {idx} | Class: {labels[label]}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5507b43",
   "metadata": {},
   "source": [
    "## 5. Frame Statistics\n",
    "\n",
    "Analyze video properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dir.exists() and 'train' in datasets:\n",
    "    dataset = datasets['train']\n",
    "\n",
    "    # Sample a few videos and check properties\n",
    "    sample_size = min(20, len(dataset))\n",
    "\n",
    "    shapes = []\n",
    "    for i in range(sample_size):\n",
    "        video, _ = dataset[i]\n",
    "        shapes.append(video.shape)\n",
    "\n",
    "    print(f\"Sampled {sample_size} videos:\")\n",
    "    print(f\"  Frame shape (T, C, H, W): {shapes[0]}\")\n",
    "    print(f\"  Consistent shapes: {len(set(shapes)) == 1}\")\n",
    "\n",
    "    # Pixel value range\n",
    "    video, _ = dataset[0]\n",
    "    print(\"\\nPixel value range:\")\n",
    "    print(f\"  Min: {video.min():.3f}\")\n",
    "    print(f\"  Max: {video.max():.3f}\")\n",
    "    print(f\"  Mean: {video.mean():.3f}\")\n",
    "    print(f\"  Std: {video.std():.3f}\")\n",
    "else:\n",
    "    print(\"No data to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0f576",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "After exploring the data:\n",
    "\n",
    "1. **Address class imbalance** (if present):\n",
    "   - Use class weights in loss function\n",
    "   - Apply oversampling or undersampling\n",
    "   - Consider focal loss\n",
    "\n",
    "2. **Prepare for training**:\n",
    "   - Review augmentation strategy in config\n",
    "   - Select appropriate model architecture\n",
    "   - Set training hyperparameters\n",
    "\n",
    "3. **Start training**:\n",
    "   ```bash\n",
    "   python -m src.cli train --config configs/default.yaml\n",
    "   ```\n",
    "\n",
    "4. **Monitor training**:\n",
    "   - Check logs in `logs/`\n",
    "   - Monitor training curves\n",
    "   - Watch for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade6195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
